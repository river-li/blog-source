python音频处理有许多的模块，首先了解音频的相关知识，之后主要看一下wave库和LibROSA库的用法


<!--more-->


### 音频基础知识

首先需要了解**奈奎斯特采样定律**

> 想要完整保留原始信号中的信息，需要采样频率大于信号中最高频率的两倍

而人耳的听力范围是20~20kHZ

音频文件主要有这么几类格式

- 标准格式 WAV，采样频率是44.1kHZ
- 有损编码 MP3等
- 无损编码 APE、FLAC

在数据分析中，提取音频特征时可能有以下指标

#### MFCC

梅尔频率倒谱系数时基于人耳频率提出的，它与频率成非线性对应关系
$$
m=256log_{10}(1+\frac{f}{700})
$$
当频率在1000Hz以下时人耳听觉能力随频率线性增长

而当频率超过1000Hz时，听觉能力与频率呈对数增长

MFCC是利用这个特点计算得到的特征，可以用于特征提取和数据降维

特征计算的过程：

- 傅里叶变换
- 使用Mel滤波器组滤波
- 对数运算
- DCT变换，得到Mel参数



#### Chroma

Chroma色度特征是色度向量(Chroma Vector)和色度图谱(Chromagram)的总称

色度图谱是色度向量的序列

色度向量可以理解为将声音用12个元素的向量表示

这12个向量是音乐中do,re,mi...si共7个白键以及另外5个半音的黑键组成

不同八度同样的音是向量中同一个元素的能量累加得到的

因此用这个12维的向量即可表示某个时间点的声音

而向量随时间组成的序列即为色度图谱



特征计算的步骤：

- 首先对音频文件傅里叶变换
- 降噪
- 将不同的声音定频到钢琴固定的频率
- 记录每一个音高在每一帧内的能量，得到音高图谱
- 将同一时间不同八度音符的能量叠加到相同的音级，得到色度图谱

### wave

这个库是python自带的音频处理的库

不需要单独安装

```python
f = wave.open(filename,mode)
```

读取文件的函数就和常规的open类似，参数分别是文件名和打开的模式(读写等)

```python
params = f.getparams()
```

返回的结果是一个类的对象,内容是打开的文件的各个参数

各个参数依次是

- nchannels 声道数
- sampwidth 位深度，返回的结果是字节数
- framerate 采样频率，wav文件固定是44.1K
- nframes 采样点数
- comtype 是否被压缩
- compname 压缩类型

返回的这些结果可以作为对象的属性获取，也可以像访问列表一样获取

![1.png][1]



```python
data = f.readframe(nframes)
```

这个nframes是音频的采样点个数，这个数据和文件采样频率和长度有关

返回的结果是读取到的波形数据

这个数据是bytes格式的，由一串16进制的字符串组成

注意，wave.open打开的文件同样也需要close

```python
f.close()
```



下面使用matplotlib对数据进行绘图

以上面的音乐文件为例

```python
import matplotlib.pyplot as plt
import numpy as np
wave_data = np.frombuffer(data,dtype=np.short)
wave_data.shape=-1,2
#由于wav文件位深度16位，因此可以用short表示
time = np.arange(0,params.nframes)*(1.0/params.framerate)
plt.subplot(211)
plt.plot(time,wave_data.T[0])
plt.subplot(212)
plt.plot(time,wave_data.T[1],c='g')
plt.show()
```

由于音乐文件有两个声道，将其转换到np的数组后进行转置

两项数据分别对应两个声道

绘制的结果如图

![2.png][2]

### LibROSA

LibROSA是一个用于音乐分析的库

整个库下面又分成很多个模块,下面用到哪个说哪个

```python
y,sr=librosa.load(filename)
```

返回的两个结果中y是采样的数据，sr是采样频率

这个函数默认的采样频率是22050，如果要使用文件原本的频率需要增加参数

`librosa.load(filename,sr=None)`

![3.png][3]

#### librosa.beat

这个模块是librosa中用于分析节拍的模块

```python
y,sr = librosa.load('music.wav')
#结果中y是数据，sr是采样频率
tempo,beat_frames = librosa.beat.beat_track(y=y,sr=sr)
# tempo是每分钟的节拍数
# beat_frames 是节拍发生的帧
beat_times = librosa.frames_to_time(beat_frames,sr=sr)
```

最后会得到一个数组，相当于是每一个节拍发生的时间戳信息，单位是秒

![4.png][4]



#### librosa.feature

这个模块中内置了很多特征的计算方法

使用这个模块来计算音乐的MFCC值和Chroma值

```python
y,sr = librosa.load('music.wav')
hop = 512
mfcc = librosa.feature.mfcc(y=y,sr=sr,hop_length=hop,n_mfcc=13)
```

计算得到的mfcc值

![5.png][5]

```python
chroma_cq = librosa.feature.chroma_cqt(y=y,sr=sr)
```

虽然计算chroma值的api调用起来很简单，但是在使用这个函数之前还需要首先过滤掉音乐中的冲击信号

这一步可以使用librosa.effects.hpss进行处理

```python
y_harmonic,y_percussive = librosa.effects.hpss(y)
```

得到的chroma值

![6.png][6]


[1]: http://42.193.111.59/usr/uploads/2021/01/1245749184.png#vwid=163&vhei=407
[2]: http://42.193.111.59/usr/uploads/2021/01/59430565.png#vwid=640&vhei=480
[3]: http://42.193.111.59/usr/uploads/2021/01/2181266477.png#vwid=602&vhei=209
[4]: http://42.193.111.59/usr/uploads/2021/01/3124379733.png#vwid=588&vhei=750
[5]: http://42.193.111.59/usr/uploads/2021/01/2554184949.png#vwid=703&vhei=547
[6]: http://42.193.111.59/usr/uploads/2021/01/2304602353.png#vwid=687&vhei=412