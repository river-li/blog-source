该部分对应文章中的第六章到第八章

商用反病毒引擎可能存在的缺点在于我们不清楚其中具体实现的原理

在部分情况下需要对结果的比例进行调整时有一个自己构建的系统还是更加方便

## 原理

该部分对应书中内容第六章

机器学习的方法和传统的算法有明显的思想上的区别

传统的算法是具体的步骤和指令

而机器学习是使用样本例子来给程序示范

机器学习的步骤:

- 收集数据
- 提取特征
- 训练分类器
- 测试验证

提取特征判断是否是恶意程序的几个点:

- 是否有数字签名
- 是否出现了恶意格式的文件头
- 是否出现了加密的数据
- 是否在100台以上计算机上出现

选择合适的样本
- 数量不要太多
- 具有代表性
- 能够代表分类

机器学习分类的任务就是在特征空间中划分一个分界面，区分两个面中的样本

这个面称为决策面

最简单的两种分界方法：线性回归、K邻近

评价分类效果的好坏，要看是否有过拟合和欠拟合

### 常用的算法

#### 逻辑回归

适用于简单样本，即可以通过一条线或一个面来将样本分开

```python
def logistic_regression(compressed_data, supicious_calls, learned_parameters):
    compressed_data = compressed_data * learned_parameters["compressed_data_eight"]
    suspicious_calls = supicious_calls * learned_parameters["supicious_calls_weight"]
    score = compressed_data + supicious_calls + bias
    return logistic_function(score)

def logistic_function(score):
    return 1/(1.0+math.e**(-score))
```


#### K 邻近算法

- 提取二进制特征，找到在特征空间中距离最近的k个样本
- 计算这k个样本中恶意样本的数量，根据这个比例判定是否是恶意样本

当样本分布不均匀但是成堆分布时可以考虑用这个方法


#### 决策树

决策树算法本质上是一层一层的if判断，因此根节点的选择比较重要

根节点应该是能将yes和no区分开的一个节点，最好接近50的比例

决策树算法在预测未见过的样本时一般效果不太好，所以应用比较少

```pseudocode
tree = Tree()
def add_question(training_examples):
    question = pick_best_question(training_examples)
    uncertainty_yes,yes_samples = ask_question(question, training_examples, "yes")
    uncertainty_no, no_samples = ask_question(question, training_examples, "no")
    if not uncertainty_yes < MIN_UNCERTAINTY:
        add_question(yes_samples)
    if not uncertainty_no < MIN_UNCERTAINTY:
        add_question(no_samples)

add_question(training_examples)
```

#### 随机森林

随机森林算法是决策树的升级版，一次同时训练的不是一棵树而是几百上千个决策树

最后令每一个决策树来投票

生成随机森林的过程：

- 训练：对每一个树
    - 随机从训练样本集中选择一些样本
    - 建立一棵决策树
    - 对每一个树，在考虑问题时只考虑部分特征，舍弃其他的特征
- 检测：
    - 对每一棵树运行检测样本的算法
    - 通过令所有的树投票决定最终分类
